import json
import os
from typing import Dict, Any, List
import psycopg2
import openai
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus

def search_wikipedia(query: str, subject: str) -> Dict[str, Any]:
    '''–ü–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ Wikipedia API'''
    try:
        wiki_url = "https://ru.wikipedia.org/w/api.php"
        params = {
            'action': 'query',
            'format': 'json',
            'list': 'search',
            'srsearch': f"{query} {subject}",
            'srlimit': 3
        }
        response = requests.get(wiki_url, params=params, timeout=5)
        data = response.json()
        
        results = []
        if 'query' in data and 'search' in data['query']:
            for item in data['query']['search'][:2]:
                results.append({
                    'title': item['title'],
                    'snippet': item['snippet'].replace('<span class="searchmatch">', '').replace('</span>', '')[:300]
                })
        
        return {'source': 'Wikipedia', 'results': results}
    except:
        return {'source': 'Wikipedia', 'results': []}

def search_wolfram_alpha(query: str) -> Dict[str, Any]:
    '''–ü–æ–∏—Å–∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö/–Ω–∞—É—á–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ Wolfram Alpha'''
    try:
        url = f"https://api.wolframalpha.com/v1/result?appid=DEMO&i={quote_plus(query)}"
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            return {'source': 'Wolfram Alpha', 'answer': response.text[:500]}
        return {'source': 'Wolfram Alpha', 'answer': None}
    except:
        return {'source': 'Wolfram Alpha', 'answer': None}

def search_multiple_sources(query: str, subject: str) -> Dict[str, List]:
    '''–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º'''
    all_results = {
        'wikipedia': [],
        'wolfram': None,
        'verified_sources': []
    }
    
    wiki_data = search_wikipedia(query, subject)
    all_results['wikipedia'] = wiki_data.get('results', [])
    
    if subject == '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞' or subject == '–§–∏–∑–∏–∫–∞':
        wolfram_data = search_wolfram_alpha(query)
        all_results['wolfram'] = wolfram_data.get('answer')
    
    trusted_domains = {
        '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞': ['math-prosto.ru', 'mathprofi.ru', 'math.ru'],
        '–§–∏–∑–∏–∫–∞': ['fizmat.vspu.ru', 'physics.ru', 'class-fizika.ru'],
        '–•–∏–º–∏—è': ['hemi.nsu.ru', 'chem.msu.su', 'chemistry.ru'],
        '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫': ['gramota.ru', 'rus.1sept.ru', 'russkiiyazyk.ru'],
        '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞': ['briefly.ru', 'lit-helper.com', 'literaguru.ru'],
        '–ë–∏–æ–ª–æ–≥–∏—è': ['bio.1sept.ru', 'biology.ru', 'biofile.ru']
    }
    
    domains = trusted_domains.get(subject, [])
    for domain in domains[:2]:
        try:
            search_url = f"https://www.google.com/search?q={quote_plus(f'{query} site:{domain}')}"
            headers = {'User-Agent': 'Mozilla/5.0'}
            resp = requests.get(search_url, headers=headers, timeout=3)
            if resp.status_code == 200:
                all_results['verified_sources'].append(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {domain}")
        except:
            pass
    
    return all_results

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    '''
    Business: –†–µ—à–∞–µ—Ç —à–∫–æ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å –ø–æ–º–æ—â—å—é OpenAI GPT-4 –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    Args: event - dict —Å httpMethod, body (question, subject)
          context - –æ–±—ä–µ–∫—Ç —Å request_id
    Returns: HTTP response —Å —Ä–µ—à–µ–Ω–∏–µ–º –∑–∞–¥–∞—á–∏
    '''
    method: str = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Max-Age': '86400'
            },
            'body': '',
            'isBase64Encoded': False
        }
    
    if method != 'POST':
        return {
            'statusCode': 405,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'Method not allowed'}),
            'isBase64Encoded': False
        }
    
    body_data = json.loads(event.get('body', '{}'))
    question: str = body_data.get('question', '')
    subject: str = body_data.get('subject', '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞')
    
    if not question.strip():
        return {
            'statusCode': 400,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'Question is required'}),
            'isBase64Encoded': False
        }
    
    openai_key = os.environ.get('OPENAI_API_KEY')
    if not openai_key:
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'OpenAI API key not configured'}),
            'isBase64Encoded': False
        }
    
    openai.api_key = openai_key
    
    search_results = search_multiple_sources(question, subject)
    
    context_parts = []
    context_parts.append("=" * 80)
    context_parts.append("–ü–†–û–í–ï–†–ï–ù–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò –ú–ò–†–û–í–û–ì–û –£–†–û–í–ù–Ø:")
    context_parts.append("=" * 80)
    
    if search_results['wikipedia']:
        context_parts.append("\nüìö WIKIPEDIA (—ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—è):")
        for idx, wiki in enumerate(search_results['wikipedia'], 1):
            context_parts.append(f"{idx}. {wiki['title']}")
            context_parts.append(f"   {wiki['snippet'][:250]}")
    
    if search_results['wolfram']:
        context_parts.append("\nüî¨ WOLFRAM ALPHA (–Ω–∞—É—á–Ω—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä):")
        context_parts.append(f"   –¢–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç: {search_results['wolfram'][:200]}")
    
    if search_results['verified_sources']:
        context_parts.append("\n‚úÖ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê:")
        for source in search_results['verified_sources']:
            context_parts.append(f"   ‚Ä¢ {source}")
    
    context_parts.append("\n" + "=" * 80)
    context_text = "\n".join(context_parts) if context_parts else ""
    
    system_prompts = {
        '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞': '–¢—ã - –∞–∫–∞–¥–µ–º–∏–∫ –†–ê–ù –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ, —ç–∫—Å–ø–µ—Ä—Ç –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã. –¢–æ—á–Ω–æ—Å—Ç—å - –ø—Ä–µ–≤—ã—à–µ –≤—Å–µ–≥–æ.',
        '–§–∏–∑–∏–∫–∞': '–¢—ã - –Ω–æ–±–µ–ª–µ–≤—Å–∫–∏–π –ª–∞—É—Ä–µ–∞—Ç –ø–æ —Ñ–∏–∑–∏–∫–µ. –ü—Ä–∏–º–µ–Ω—è–π —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã —Ñ–∏–∑–∏–∫–∏ —Å –∞–±—Å–æ–ª—é—Ç–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é. –ü—Ä–æ–≤–µ—Ä—è–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.',
        '–•–∏–º–∏—è': '–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä —Ö–∏–º–∏–∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω—ã–µ —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —É—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∞–∫—Ü–∏–π.',
        '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫': '–¢—ã - –ª–∏–Ω–≥–≤–∏—Å—Ç, –∞–≤—Ç–æ—Ä —É—á–µ–±–Ω–∏–∫–æ–≤ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É. –ü—Ä–∏–º–µ–Ω—è–π –ø—Ä–∞–≤–∏–ª–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.',
        '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞': '–¢—ã - –¥–æ–∫—Ç–æ—Ä —Ñ–∏–ª–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –Ω–∞—É–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–≤–µ–¥—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π.',
        '–ë–∏–æ–ª–æ–≥–∏—è': '–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä –±–∏–æ–ª–æ–≥–∏–∏, —á–ª–µ–Ω –Ω–∞—É—á–Ω–æ–π –∞–∫–∞–¥–µ–º–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –Ω–∞—É—á–Ω–æ –¥–æ–∫–∞–∑–∞–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã.'
    }
    
    system_content = system_prompts.get(subject, '–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤ —Å–≤–æ–µ–π –æ–±–ª–∞—Å—Ç–∏. –¢–æ—á–Ω–æ—Å—Ç—å –∏ –Ω–∞—É—á–Ω–æ—Å—Ç—å - —Ç–≤–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç.')
    
    prompt = f"""üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –î–∞–π –°–ê–ú–´–ô –¢–û–ß–ù–´–ô –û–¢–í–ï–¢ –í –ú–ò–†–ï!

–ò—Å–ø–æ–ª—å–∑—É–π –í–°–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∏–∂–µ:

{context_text}

üìã –ó–ê–î–ê–ß–ê:
–ü—Ä–µ–¥–º–µ—Ç: {subject}
–í–æ–ø—Ä–æ—Å: {question}

‚ö° –¢–†–ï–ë–û–í–ê–ù–ò–Ø (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û):
1. ‚úÖ –°–í–ï–†–Ø–ô –∫–∞–∂–¥—ã–π —à–∞–≥ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ Wikipedia, Wolfram Alpha –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
2. ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã, –ø—Ä–∞–≤–∏–ª–∞ –∏ —Ñ–∞–∫—Ç—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤—ã—à–µ
3. ‚úÖ –ï—Å–ª–∏ Wolfram Alpha –¥–∞–ª –æ—Ç–≤–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –∫–∞–∫ —ç—Ç–∞–ª–æ–Ω
4. ‚úÖ –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—å —Ä–∞—Å—á–µ—Ç—ã –¢–†–ò–ñ–î–´
5. ‚úÖ –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ø–æ –¥–∞–Ω–Ω—ã–º Wikipedia...")
6. ‚úÖ –î–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
7. ‚úÖ –í —Ñ–∏–Ω–∞–ª–µ - —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è

üéì –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ markdown:
{{
  "answer": "–∞–±—Å–æ–ª—é—Ç–Ω–æ —Ç–æ—á–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç",
  "steps": [
    "–®–∞–≥ 1: [–∏—Å—Ç–æ—á–Ω–∏–∫] –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º—É–ª–∞–º–∏",
    "–®–∞–≥ 2: —Ç–æ—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º",
    "–®–∞–≥ 3: –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
    "..."
  ],
  "confidence": "99%",
  "sources_verified": ["Wikipedia", "Wolfram Alpha", "—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∞–π—Ç—ã"]
}}"""
    
    response = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[
            {'role': 'system', 'content': system_content},
            {'role': 'user', 'content': prompt}
        ],
        temperature=0.1
    )
    
    response_content = response.choices[0].message['content']
    
    if response_content.startswith('```'):
        response_content = response_content.split('```')[1]
        if response_content.startswith('json'):
            response_content = response_content[4:]
    
    solution_json = json.loads(response_content.strip())
    answer = solution_json.get('answer', '')
    steps = solution_json.get('steps', [])
    confidence = solution_json.get('confidence', '95%')
    sources_verified = solution_json.get('sources_verified', [])
    
    verification_text = f"üåç –¢–æ—á–Ω–æ—Å—Ç—å: {confidence} | –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: "
    if search_results['wikipedia']:
        verification_text += "Wikipedia ‚úì "
    if search_results['wolfram']:
        verification_text += "Wolfram Alpha ‚úì "
    if search_results['verified_sources']:
        verification_text += "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∞–π—Ç—ã ‚úì"
    
    steps.append(verification_text)
    
    db_url = os.environ.get('DATABASE_URL')
    if db_url:
        conn = psycopg2.connect(db_url)
        cur = conn.cursor()
        
        steps_json = json.dumps(steps, ensure_ascii=False)
        
        cur.execute(
            "INSERT INTO solutions (subject, question, answer, steps) VALUES (%s, %s, %s, %s) RETURNING id",
            (subject, question, answer, steps_json)
        )
        solution_id = cur.fetchone()[0]
        
        conn.commit()
        cur.close()
        conn.close()
    else:
        solution_id = 0
    
    result = {
        'id': str(solution_id),
        'subject': subject,
        'question': question,
        'answer': answer,
        'steps': steps
    }
    
    return {
        'statusCode': 200,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps(result, ensure_ascii=False),
        'isBase64Encoded': False
    }